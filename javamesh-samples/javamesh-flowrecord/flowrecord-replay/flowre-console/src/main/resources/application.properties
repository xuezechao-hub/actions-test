server.port=8090
# zookeeper地址，集群模式各ip以逗号分隔
zookeeper.client=127.0.0.1:2181
# elasticsearch地址，集群模式各ip以逗号分隔
elasticsearch.hostList=127.0.0.1:9200
# 获取所有应用的名字，心跳模块以该值作为key值，按set存app名字
appnameKey=appnames
# heartbeat suffix flag in redis
heartbeatflag=:heartbeat
# elasticsearch user name
elasticsearch.userName=elastic
# elasticsearch password
elasticsearch.passwd=FlowRecord@2021

#disruptor
disruptor.ringbuffer.size=2048
#heartbeat suffix flag in redis
#metric suffix flag in redis
metricflag=:metric
#topic names
topics=topic-heartbeat

#初始化partions数
partitions.init=3
#初始化副本数#redis
replication-factor.init=1
#kafka消费者一次拉取时的超时时间
kafka.consumer.poll.timeout=1000
#重平衡时设置的安全偏移量，以防丢数据，即便可能是重复消费
kafka.consumer.rebalance.safeOffset=0
#kafka消费者业务处理使用线程池处理时的线程数
kafka.consumer.threadPool.threads=10
#kafka消费者业务处理使用线程池处理时的核心线程数
kafka.consumer.threadPool.coreThreads=5
#kafka消费者业务处理使用线程池处理时的阻塞队列的大小
kafka.consumer.threadPool.blockingQueueSize=5
#是否开启集群
spring.redis.isCluster=false
#redis设置数据过期时间
redis.data.timeout=1
#redis设置规则数据过期时间
redis.rule.data.timeout=500info
#日志级别
logging.level.root=
#redis
#redis数据库
spring.redis.database=0
#redis主机名172.31.96.180
spring.redis.host=127.0.0.1
#redis密码
spring.redis.password=
#FlowRecord@2021
#redis端口号
spring.redis.port=6379
#连接超时时间
spring.redis.timeout=60000
#连接池中连接的最大等待的连接数
spring.redis.lettuce.pool.max-wait=100
#连接池中连接的最大空闲数
spring.redis.lettuce.pool.max-idle=10
#连接池中连接的最大活跃数
spring.redis.lettuce.pool.max-active=40
#连接池中连接的最小空闲数
spring.redis.lettuce.pool.min-idle=1
#跨群集执行命令时要遵循的最大重定向数
spring.redis.cluster.max-redirects=5
#集群节点
spring.redis.cluster.nodes=
#172.31.90.27:7001,172.31.90.36:7002,172.31.90.67:7003,172.31.90.27:7004,172.31.90.36:7005,172.31.90.67:7006
#192.168.188.129:7000,192.168.188.129:7001,192.168.188.129:7002,192.168.188.130:7003,192.168.188.130:7004,192.168.188.130:7005
#172.31.96.180:7001,172.31.96.64:7002,172.31.96.39:7003,172.31.96.180:7004,172.31.96.64:7005,172.31.96.39:7006
#172.31.90.179:7001,172.31.90.236:7002,172.31.90.22:7003,172.31.90.179:7004,172.31.90.236:7005,172.31.90.22:7006
#172.31.90.27:7001,172.31.90.36:7002,172.31.90.67:7003,172.31.90.27:7004,172.31.90.36:7005,172.31.90.67:7006
#kafka
#kafka服务器的地址，可以是以逗号“，”隔开的多个地址
#172.31.96.79:9092
spring.kafka.bootstrap-servers=127.0.0.1:9092
#vm 192.168.188.129:9092,192.168.188.130:9092,192.168.188.131:9092
#oldTest 172.31.96.64:9092,172.31.96.180:9092,172.31.96.79:9092
#dev 172.31.90.56:9092,172.31.90.110:9092,172.31.90.7:9092
#test 172.31.90.213:9092,172.31.90.229:9092,172.31.90.89:9092
#生产者重试次数
spring.kafka.producer.retries=5
#请求超时时间
spring.kafka.producer.properties.request.timeout.ms=1000000
#参数用来指定分区中必须要有多少个副本收到这条消息，之后生产者才会认为这条消息是成功写入的。
#acks=1，默认值，表示只要leader副本成功写入消息，那么它就会收到来自服务端的成功响应
#acks=0，生产者发送消 息之后不需要等待任何服务端的响应
#acks=-1，或者all。生产者在消 息发送之后，需要等待 ISR 中的所有副本都成功写入消息之后才能够收到来自服务端的成功响应。
spring.kafka.producer.acks=all
#消息在网络上都是以字节 （Byte）的形式传输的，在发送之前需要创建一块内存区域来保存对应的消息 。BufferPool放入的bytebuffer的大小就是
#由该参数指定的。默认值为 16384B ，即 16KB
spring.kafka.producer.batch-size=16384
#RecordAccumulator缓存的大小可以通过生产者客户端参数buffer.memory配置，默认值为 33554432B ，即 32MB。
spring.kafka.producer.buffer-memory=33554432
#开启事务
#spring.kafka.producer.transaction-id-prefix=transaction-id-
#键的序列化类
spring.kafka.producer.key-serializer=org.apache.kafka.common.serialization.StringSerializer
#值得序列化类
spring.kafka.producer.value-serializer=org.apache.kafka.common.serialization.StringSerializer
#开启幂等性
spring.kafka.producer.properties.enable.idempotence=true
#组id
spring.kafka.consumer.group-id=group1
#在Kafka中每当消费者查找不到所记录的消费位移 时， 就会根据消费者客户端参数
#aut.offset.reset的配置来决定从何处开始进行消费，这个参数的默认值为“latest”，表
#示从分区末尾开始消费消息。
spring.kafka.consumer.auto-offset-reset=latest
#是否自动提交
spring.kafka.consumer.enable-auto-commit=false
#定时提交的时间间隔
spring.kafka.consumer.auto-commit-interval=100
#消费者一次最大拉取的记录数
spring.kafka.consumer.max-poll-records=2000
#消费者一次拉取的最小字节数
spring.kafka.consumer.fetch-min-size=33554432
#两次拉取的最大间隔时间
spring.kafka.consumer.properties.max.poll.interval.ms=300000
#请求超时时间
spring.kafka.consumer.properties.request.timeout.ms=40000
#coordinator检测失败的时间
spring.kafka.consumer.properties.session.timeout.ms=30000
#开启正则匹配方式的订阅主题
spring.kafka.consumer.properties.exclude.internal.topics=false
#隔离级别
spring.kafka.consumer.properties.isolation.level=read_committed
#键的反序列化类
spring.kafka.consumer.key-deserializer=org.apache.kafka.common.serialization.StringDeserializer
#值的反序列化类
spring.kafka.consumer.value-deserializer=org.apache.kafka.common.serialization.StringDeserializer
#线程池配置
#核心线程数
corePoolSize=20
#最大线程数
maximumPoolSize=30
#闲置线程存活时间
keepAliveTime=2000
#jedis的设置
#最大连接数
jedisPoolConfig.setMaxTotal=300
#最大空闲连接数
jedisPoolConfig.setMaxIdle=200
#获取连接时的最大等待毫秒数
jedisPoolConfig.setMaxWaitMillis=3000
#连接超时时间
jedisPoolConfig.connectionTimeout=20000
#读取数据超时时间
jedisPoolConfig.soTimeout=2000
#异常重试的次数
jedisPoolConfig.maxAttempts=10
#定时操作的时间间隔
scheduleTime=1000
#批量发送数据的数据量
pipelineNum=2000

